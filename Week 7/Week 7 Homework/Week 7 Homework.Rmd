---
title: "Week 7 Open Intro Exercises and Lab"
author: "Steven Simonsen"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(statsr)
library(broom)
```

### Exercise 1: What are the dimensions of the dataset? What does each row represent?

The dimensions of the dataset are variables representing freedom (123 variables) for many countries across the globe. Each row represents a unique country (1,458 in total) by year, and the unique measurements of each variable for said country in a given year to measure freedom.

```{r code-chunk-label}
```

### Exercise 2: The dataset spans a lot of years, but we are only interested in data from year 2016. Filter the data hfi data frame for year 2016, select the six variables, and assign the result to a data frame named hfi_2016.
```{r}
set.seed(1223)
hfi_2016data <- hfi %>%
  filter(year=="2016") #Filter the data to 2016 only

hfi_varselect <- hfi_2016data %>%
  select(year, ISO_code, countries, region, pf_expression_control, pf_score, hf_score, ef_legal_courts) #6 total variables based on descriptions of dataset variables found on https://www.openintro.org/data/index.php?data=hfi

hfi_2016 <- data.frame(hfi_varselect) #Assign to Data Frame
```
## Exercise 3: What type of plot would you use to display the relationship between the personal freedom score, pf_score, and pf_expression_control? Plot this relationship using the variable pf_expression_control as the predictor. Does the relationship look linear? If you knew a country’s pf_expression_control, or its score out of 10, with 0 being the most, of political pressures and controls on media content, would you be comfortable using a linear model to predict the personal freedom score?
As a preliminary means to see if the the relationship between pf_expression_control (predictor) and pf_score "looks" linear, I would create a scatterplot of the data with a least squares line overlaid on top. As can be seen in the result of the linear model performed, the data shows a relatively small standard error and statistically significant p-value of less than .05. Based on the linear model performed, and the scatterplot created with the least squares line laid on top, the relationship does appear to look linear. However, I would also want to perform additional analysis to check for the additional conditions of linear modeling to be met below to fully assess the data. Based on this preliminary analysis, I would feel comforatable using pf_expression_control as a linear model to predict the personal freedom score. 

Conditions for linear models:

1 Since residuals are squared, the assumption follows that residuals are normally distributed

  - Otherwise you will have influential points who weight the slope of the line!
  
2 More rows than columns

3 Linear relationship

4 Homoscedasticity of residuals or equal variance

  - No pattern in the residuals
  
5 No auto-correlation of residuals

6 No multivariate multicollinearity (not needed for this example)

```{r}
set.seed(1223)  
library(Metrics)
library(corrplot)
library(car)

mod <- lm(pf_score~pf_expression_control, hfi_2016)
summary(mod)

plot(hfi_2016$pf_score ~ hfi_2016$pf_expression_control)
abline(mod)

hfi_2016 %>%
  summarise(cor(pf_expression_control, pf_score)) #The strength of the relationship with the correlation coefficient is 0.845
```
## Exercise 4: Looking at your plot from the previous exercise, describe the relationship between these two variables. Make sure to discuss the form, direction, and strength of the relationship as well as any unusual observations.

Based on the scatter plot created in the previous exercise, there appears to be a moderate to strong, positive, linear relationship between pf_expression_control and pf_score. There are some outliers impacting the graph, most notibly on the left side of the graph nearest the intercept.

## Exercise 5: Using plot_ss, choose a line that does a good job of minimizing the sum of squares. Run the function several times. What was the smallest sum of squares that you got? How does it compare to your neighbours?
The smallest sum of squares that I got was 102.805. I ran the function three times, and compared to the other two times I ran it I got 106.153 and 111.221. In other words, the line that least minimizes the sum of squared residuals is the one where the sum of squares=102.805.
```{r}
#First Attempt- Sum of Squares=106.153
plot_ss(x = pf_expression_control, y = pf_score, data = hfi_2016, showSquares = TRUE) 
```
```{r}
#Second Attempt- Sum of Squares=102.805
plot_ss(x = pf_expression_control, y = pf_score, data = hfi_2016, showSquares = TRUE)
```
```{r}
#Third Attempt - Sum of Squares=111.221
plot_ss(x = pf_expression_control, y = pf_score, data = hfi_2016, showSquares = TRUE)
```
## Exercise 6: Fit a new model that uses pf_expression_control to predict hf_score, or the total human freedom score. Using the estimates from the R output, write the equation of the regression line. What does the slope tell us in the context of the relationship between human freedom and the amount of political pressure on media content?
y^=5.05 + 0.368 x pf_expression_control

The slope tells us that for every 1 unit increase in pf_expression_control, we can expect a country's mean human freedom score to increase 0.368 units.

```{r}
mod2 <- lm(hf_score~pf_expression_control, hfi_2016)
tidy(mod2)
```
## Exercise 7: If someone saw the least squares regression line and not the actual data, how would they predict a country’s personal freedom school for one with a 3 rating for pf_expression_control? Is this an overestimate or an underestimate, and by how much? In other words, what is the residual for this prediction?
If somebody only saw the least squares regression line and not the actual data, they would predict a country's personal freedom score to be 6.5 for one with a 3 rating for pf_expression Control. This is an overestimate by 0.594 for this value. In other words, the residual is 0.594. See math below:
y^=4.28 + 0.542 * 3
y^=5.906

The value observed by looking at the line is 6.5. The difference between these values is 0.594.

```{r}
ggplot(data = hfi_2016, aes(x = pf_expression_control, y = pf_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE)
```

## Exercise 8: Is there any apparent pattern in the residuals plot? What does this indicate about the linearity of the relationship between the two variables?
The pattern most apparent is the grouping from larger to smaller variability of the residuals. In other words, there are more outliers and values further away from y=0 on the left side of the graph, which may violate the linear condition of nearly normal residuals within the data.
```{r}
mod_aug <- augment(mod)

ggplot(data = mod_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  xlab("Fitted values") +
  ylab("Residuals")
```

## Exercise 9: Based on the histogram, does the nearly normal residuals condition appear to be violated? Why or why not?
Based on the histogram, the nearly normal residuals condition appears to be violated. There is a heavy tail on the left side of the dataset, resulting in too many extreme negative residuals. Therefore, I would conclude that the relationship between pf_expression control (predictor) and pf_score is not linear. 
```{r}
ggplot(data = mod_aug, aes(x = .resid)) +
  geom_histogram(binwidth = 0.25) +
  xlab("Residuals")
```

## Exercise 10: Based on the residuals vs. fitted plot, does the constant variability condition appear to be violated? Why or why not?

Yes, since the residual values are much greater (or further away from the y=0 dotted line) on the left side of the graph than the right, the constant variability condition appears to be violated.

## Additional Practice

## 1) Choose another variable that you think would strongly correlate with pf_score. Produce a scatterplot of the two variables and fit a linear model. At a glance, does there seem to be a linear relationship?
I chose the variable, ef_legal_courts which measures how impartial the courts system is for a given country. At a glance, there does not appear to be a strong fit, as there are values both far above and below the fitted line.

```{r}
mod3 <- lm(ef_legal_courts~pf_expression_control, hfi_2016)
summary(mod3)

plot(hfi_2016$ef_legal_courts ~ hfi_2016$pf_expression_control)
abline(mod3)
```

## 2) How does this relationship compare to the relationship between pf_score and pf_expression_control? Use the R2 values from the two model summaries to compare. Does your independent variable seem to predict pf_score better? Why or why not?
The R2 value between my independent variable (ef_legal_courts) and pf_score is .0876. This is significantly worse than the independent pf_expression_control variable because it means that only 8.76% of the variance is explained by the variables in the regression model chosen. Additionally, the correlation coefficient is only .308, as opposed to .845 when comparing to the model using pr_expression_control.

```{r}
hfi_2016 %>%
  summarise(cor(ef_legal_courts, pf_score))

glance(mod3)
```
## 3) Check the model diagnostics using appropriate visualisations and evaluate if the model conditions have been met.
Upon examining the various graphs below, the model conditions do appear to be met. The residuals do not appear to show patterns, are relatively normally distributed, etc. 
```{r}
mod_aug3 <- augment(mod3)

ggplot(data = mod_aug3, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  xlab("Fitted values") +
  ylab("Residuals")

ggplot(data = mod_aug3, aes(x = .resid)) +
  geom_histogram(binwidth = 0.25) +
  xlab("Residuals")

ggplot(data = hfi_2016, aes(x = ef_legal_courts, y = pf_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE)

plot(mod3)

glance(mod3)
tidy(mod3)
```
...

